import telebot
from telebot import types
import g4f
import requests
import pyttsx3
import speech_recognition as sr
import soundfile as sf
from pydub import AudioSegment
from elevenlabs import set_api_key, voices, generate, save
from elevenlabs.api import Voice, Models

API_KEY = ''
set_api_key(API_KEY)
voice_id_serg = ''
voice_id_helena = ''
voice_id_kirk = ''

# voices = voices()

voice = Voice.from_id(voice_id_kirk)
voice.settings.stability = 0.3

def generate_my_voice(text):
    audio = generate(
        text=text,                # Defautls to env variable ELEVEN_API_KEY, or None if not set but quota will be limited
        voice=voice,                 # Either a voice name, voice_id, or Voice object (use voice object to control stability and similarity_boost)
        model="eleven_multilingual_v2",                                  # [1-4] the higher the more optimized for streaming latency (only works with stream=True)
    )

    save(
        audio=audio,               # Audio bytes (returned by generate)
        filename='sergey_answer.wav'               # Filename to save audio to (e.g. "sergey_answer.wav")
    )

g4f.logging = True # enable logging
g4f.check_version = False # Disable automatic version checking

bot = telebot.TeleBot('')

# engine = pyttsx3.init()

def get_answer(message):       
    response = g4f.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": f'{message}'}],
        stream=True,
    )         
    response_answer = ""
    for s in response:
        response_answer += s
    return response_answer    

# def load_message(text='–ü–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ...'):
    # bot.send_message(message.from_user.id, f'{text}', parse_mode='Markdown') # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–∞ –≤ —á–∞—Ç


@bot.message_handler(commands=['start'])
def start(message):

    markup = types.ReplyKeyboardMarkup(resize_keyboard=True)
    btn1 = types.KeyboardButton("üëã –ü–æ–∑–¥–æ—Ä–æ–≤–∞—Ç—å—Å—è")
    markup.add(btn1)
    bot.send_message(message.from_user.id, "üëã –ü—Ä–∏–≤–µ—Ç! –Ø —Ç–≤–æ–π –±–æ—Ç-–ø–æ–º–æ—à–Ω–∏–∫!", reply_markup=markup)

@bot.message_handler(content_types=['text'])
def get_text_messages(message):

    if message.text:  
        bot.send_message(message.from_user.id, '–ü–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ...', parse_mode='Markdown') # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–∞ –≤ —á–∞—Ç
        # engine.say(answer)
        answer = get_answer(message.text)
        bot.send_message(message.from_user.id, f'{answer}', parse_mode='Markdown') # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–∞ –≤ —á–∞—Ç
        # –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º —Ä–µ—á—å
        # engine.save_to_file(f'{answer}', 'answer.wav')
        # engine.runAndWait()  
        generate_my_voice(answer)
        bot.send_document(message.from_user.id, document=open("sergey_answer.wav", "rb"))
        # bot.send_audio(message.from_user.id, audio=open("answer.wav", "rb"))
    
@bot.message_handler(content_types=['voice'])
def handle_voice_message(message):
    bot.send_message(message.from_user.id, '–ü–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ...', parse_mode='Markdown') # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–∞ –≤ —á–∞—Ç
    # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    voice = message.voice
    file_info = bot.get_file(voice.file_id)
    file = bot.download_file(file_info.file_path)
    with open('voice_answer.wav', 'wb') as f:
        f.write(file)
    input_file = 'voice_answer.wav'
    output_file = 'voice_answer.flac'
    audio_data, sample_rate = sf.read(input_file)
    sf.write(output_file, audio_data, sample_rate, format='FLAC')
    r = sr.Recognizer()
    with sr.AudioFile('voice_answer.flac') as source:
        audio_data = r.record(source)
        text = r.recognize_google(audio_data, language='ru')

        bot.send_message(message.from_user.id, f'–ò—â—É "{text}..."', parse_mode='Markdown') # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–∞ –≤ —á–∞—Ç

        answer_from_voice = get_answer(text)
        bot.send_message(message.from_user.id, f'{answer_from_voice}', parse_mode='Markdown') # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–∞ –≤ —á–∞—Ç
        
        
        bot.send_message(message.from_user.id, '–ü—Ä–æ–≥–æ–≤–æ—Ä—é –≤–∞–º –æ—Ç–≤–µ—Ç...', parse_mode='Markdown') # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–∞ –≤ —á–∞—Ç
        # engine.save_to_file(f'{answer_from_voice}', 'answer_from_voice.wav')
        # engine.runAndWait()
        generate_my_voice(answer_from_voice)
        bot.send_document(message.from_user.id, document=open("sergey_answer.wav", "rb"))

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∞—É–¥–∏–æ—Å–æ–æ–±—â–µ–Ω–∏–π
@bot.message_handler(content_types=['audio'])
def handle_audio(message):
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ
    file_info_audio = bot.get_file(message.audio.file_id)
    file_audio = bot.download_file(file_info_audio.file_path)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –Ω–∞ –¥–∏—Å–∫
    with open('audio_file.wav', 'wb') as audio_file:
        audio_file.write(file_audio)
    
    input_file_audio = 'audio_file.wav'
    output_file_audio = 'audio_file.flac'
    audio_data_audio, sample_rate_audio = sf.read(input_file_audio)
    sf.write(output_file_audio, audio_data_audio, sample_rate_audio, format='FLAC')    

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç
    r = sr.Recognizer()
    with sr.AudioFile('audio_file.flac') as source:
        audio_data = r.record(source)
        audio_file_text = r.recognize_google(audio_data, language='ru')  # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –Ω—É–∂–Ω—ã–π —è–∑—ã–∫

    # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    
    print(audio_file_text)
    bot.send_message(message.from_user.id, f'{audio_file_text}', parse_mode='Markdown') # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–∞ –≤ —á–∞—Ç

bot.polling(none_stop=True, interval=0) 
#–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è –¥–ª—è —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞ —á–∞—Å—Ç—å